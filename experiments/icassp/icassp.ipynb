{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"INITIALIZED\" not in locals():\n",
    "    os.getcwd()\n",
    "    os.chdir(\"../..\")\n",
    "    INITIALIZED = True\n",
    "\n",
    "# os.chdir(\"/mnt/data/code/android/collaborative-intelligence\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.subplots\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from ipywidgets import interact\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy import ndimage, signal\n",
    "\n",
    "import src.analysis.dataset as ds\n",
    "from src.analysis import plot\n",
    "from src.analysis.experimentrunner import ExperimentRunner\n",
    "from src.analysis.utils import (\n",
    "    basename_of,\n",
    "    tf_disable_eager_execution,\n",
    "    title_of,\n",
    ")\n",
    "\n",
    "tf_disable_eager_execution()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "DATASET_SIZE = 4\n",
    "data_dir = \"data\"\n",
    "\n",
    "NUM_FRAMES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = ExperimentRunner(\n",
    "    model_name=\"resnet34\",\n",
    "#     layer_name=\"conv0\",\n",
    "#     layer_name=\"bn0\",\n",
    "    layer_name=\"add_3\",\n",
    "#     layer_name=\"add_7\",\n",
    "#     model_name=\"densenet121\",\n",
    "#     layer_name=\"pool3_pool\",\n",
    "#     layer_name=\"pool4_pool\",\n",
    "    dataset_size=DATASET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "shape = runner.tensor_layout.shape\n",
    "dtype = runner.tensor_layout.dtype\n",
    "h, w, c = shape\n",
    "x_in_per_cl = 224 / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_img() -> np.ndarray:\n",
    "#     return np.array(Image.open(f\"{data_dir}/sample/sample300.jpg\"))\n",
    "    return np.array(Image.open(f\"{data_dir}/sample/sample.jpg\"))\n",
    "#     return np.array(Image.open(f\"{data_dir}/sample/sample_butterfly.jpg\"))\n",
    "\n",
    "img = sample_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_of(\n",
    "    model_name: str, layer_name: str, layer_i: int, layer_n: int\n",
    ") -> str:\n",
    "    return f\"{model_name}  {layer_name}\" # ({layer_i+1}/{layer_n})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot(theta: float) -> np.ndarray:\n",
    "    return np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta),  np.cos(theta)],\n",
    "    ])\n",
    "\n",
    "def scale(x: float, y: float) -> np.ndarray:\n",
    "    return np.array([\n",
    "        [x, 0.],\n",
    "        [0., y],\n",
    "    ])\n",
    "\n",
    "def skew(x: float, y: float) -> np.ndarray:\n",
    "    return np.array([\n",
    "        [1., x],\n",
    "        [y, 1.],\n",
    "    ])\n",
    "\n",
    "def trans(x: float, y: float) -> np.ndarray:\n",
    "    return np.array([\n",
    "        [1., 0., x],\n",
    "        [0., 1., y],\n",
    "    ])\n",
    "\n",
    "def affine33(mat23: np.ndarray) -> np.ndarray:\n",
    "    mat33 = np.eye(3, dtype=np.float32)\n",
    "    x = min(3, mat23.shape[1])\n",
    "    mat33[:2, :x] = mat23[:2, :x]\n",
    "    return mat33\n",
    "\n",
    "def affine23(mat33: np.ndarray) -> np.ndarray:\n",
    "    return mat33[:2, :3].copy()\n",
    "\n",
    "def affine_mat_from(\n",
    "    shear_x=0.0,\n",
    "    shear_y=0.0, \n",
    "    scale_x=1.0,\n",
    "    scale_y=1.0,\n",
    "    rot_deg=0.0,\n",
    "    trans_x=0.0,\n",
    "    trans_y=0.0,\n",
    "    shear_x_deg=None,\n",
    "    shear_y_deg=None,\n",
    ") -> np.ndarray:\n",
    "    if shear_x_deg is not None:\n",
    "        shear_x = np.tan(shear_x_deg * np.pi / 180.0)\n",
    "    if shear_y_deg is not None:\n",
    "        shear_y = np.tan(shear_y_deg * np.pi / 180.0)\n",
    "    \n",
    "    mat = np.eye(3, dtype=np.float32)\n",
    "    mat[:2, :2] = (\n",
    "        rot(rot_deg * np.pi / 180.0)\n",
    "        @ scale(scale_x, scale_y)\n",
    "        @ skew(shear_x, shear_y)\n",
    "    )\n",
    "    mat[:2, 2] = [trans_x, trans_y]\n",
    "    \n",
    "    return mat[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_coordinate_system(mat, src_shape, out_width, out_height, center=True, leeway=None):\n",
    "    \"\"\"\n",
    "    Applies mat to correct coordinate system.\n",
    "    \n",
    "    Leeway controls how much % of the image to zoom into,\n",
    "    after leaving enough room for rotations.\n",
    "    \"\"\"\n",
    "    mat = affine33(mat)\n",
    "    \n",
    "    out_radius = np.sqrt((out_width / 2)**2 + (out_height / 2)**2)\n",
    "    src_radius = min(src_shape[:2]) / 2\n",
    "    \n",
    "    s = 1.0\n",
    "    if leeway is not None:\n",
    "        s = out_radius / src_radius / (1 - leeway)\n",
    "        # s = (1 - leeway) * src_radius / out_radius\n",
    "    \n",
    "    # s: Source  coordinate system\n",
    "    # n: Natural coordinate system\n",
    "    y, x = np.array(src_shape[:2]) / 2\n",
    "    t_n_from_s = affine33(scale(x=s, y=-s)) @ affine33(trans(-x, -y))\n",
    "    t_s_from_n = np.linalg.inv(t_n_from_s)\n",
    "    mat = t_s_from_n @ mat @ t_n_from_s\n",
    "\n",
    "    # This is for changing the VIEW only\n",
    "    if center:\n",
    "        recenter = affine33(trans(-x, -y))\n",
    "        rescale = affine33(scale(s, s))\n",
    "        offset = affine33(trans(out_width / 2, out_height / 2))\n",
    "        mat = offset @ rescale @ recenter @ mat\n",
    "    \n",
    "    return affine23(mat)\n",
    "\n",
    "def transform(img, mat, out_width, out_height, leeway=0.0):\n",
    "    \"\"\"Apply given transformation.\"\"\"\n",
    "    mat = fix_coordinate_system(\n",
    "        mat, img.shape, out_width, out_height, center=True, leeway=leeway\n",
    "    )\n",
    "    return cv2.warpAffine(\n",
    "        img, mat, dsize=(out_width, out_height), flags=cv2.INTER_CUBIC\n",
    "    )\n",
    "\n",
    "def predict(ref_tensor, mat):\n",
    "    # mat = mat.copy()\n",
    "    mat = fix_coordinate_system(mat, (224, 224), 224, 224, center=False)\n",
    "    mat[:, 2] /= x_in_per_cl\n",
    "    # NOTE this doesn't work for some interesting reasons... too much work to fix though\n",
    "    # h, w = ref_tensor.shape[:2]\n",
    "    # mat = fix_coordinate_system(mat, (h, w), w, h, center=False)\n",
    "\n",
    "    pred = np.zeros_like(ref_tensor)\n",
    "    channels = ref_tensor.shape[-1]\n",
    "    dsize = ref_tensor.shape[:-1]\n",
    "    flags = cv2.INTER_CUBIC\n",
    "\n",
    "    for k in range(channels):\n",
    "        pred[..., k] = cv2.warpAffine(\n",
    "            ref_tensor[..., k], mat, dsize=dsize, flags=flags\n",
    "        )\n",
    "\n",
    "    return pred\n",
    "\n",
    "def run_experiment(img, transform_params_list, predict, transform, runner, leeway=0.0):\n",
    "    \"\"\"Analyzes predictability of tensor data w.r.t. input transforms.\n",
    "\n",
    "    Determine how well we can predict a target frame's tensor data based\n",
    "    on only the reference tensor and some transform parameters that\n",
    "    describe the transform from reference frame to current frame.\n",
    "    \n",
    "     - `img` is a reference image to run transform on\n",
    "     - `transform_params_list` contains args for `transform`\n",
    "     - `transform` applies `transform_arg` to image frame\n",
    "     - `predict` applies `tensor_transform` to tensor\n",
    "       (where `tensor_transform` is computed from `transform_arg`)\n",
    "    \"\"\"\n",
    "    n = len(transform_params_list) + 1\n",
    "    frames = np.zeros((n, 224, 224, 3), dtype=img.dtype)\n",
    "    frames[0] = transform(img, affine_mat_from(), 224, 224, leeway=leeway)\n",
    "    # TODO not very \"generic\"... affine_mat_from? 224? \n",
    "    \n",
    "    for i, transform_params in enumerate(transform_params_list, start=1):\n",
    "        frames[i] = transform(img, transform_params, 224, 224, leeway=leeway)\n",
    "\n",
    "    client_tensors = runner.model_client.predict(frames)\n",
    "    ref_tensor = client_tensors[0]\n",
    "\n",
    "    shape = runner.tensor_layout.shape\n",
    "    dtype = runner.tensor_layout.dtype\n",
    "\n",
    "    impulse = np.ones(shape, dtype=dtype)\n",
    "    preds = np.zeros((n - 1, *shape), dtype=dtype)\n",
    "    masks = np.zeros((n - 1, *shape), dtype=np.bool)\n",
    "\n",
    "    for i, transform_params in enumerate(transform_params_list):\n",
    "        preds[i] = predict(ref_tensor, transform_params)\n",
    "        masks[i] = predict(impulse, transform_params) != 0\n",
    "\n",
    "    diffs = preds - client_tensors[1:]\n",
    "    diffs[~masks] = 0\n",
    "    diffs_masked = diffs\n",
    "    \n",
    "    x = client_tensors[1:]\n",
    "    \n",
    "    # shape=(n,)\n",
    "    tensor_ranges = np.max(x, axis=(1, 2, 3)) - np.min(x, axis=(1, 2, 3))\n",
    "    tensor_counts = np.count_nonzero(masks, axis=(1, 2, 3))\n",
    "    tensor_sses = np.sum(diffs_masked**2, axis=(1, 2, 3))\n",
    "    tensor_mses = tensor_sses / tensor_counts\n",
    "    nrmses = np.sqrt(tensor_mses) / tensor_ranges\n",
    "    mses = nrmses  # TODO temporarily bypass\n",
    "    \n",
    "    # shape=(n, c)\n",
    "    # chan_ranges = np.max(x, axis=(1, 2)) - np.min(x, axis=(1, 2))\n",
    "    # chan_counts = np.count_nonzero(masks, axis=(1, 2))\n",
    "    # chan_sses = np.sum(diffs_masked**2, axis=(1, 2))\n",
    "    # chan_mses = chan_sses / chan_counts\n",
    "    \n",
    "    # shape=(n,)\n",
    "    # mses = np.sum(chan_sses, axis=-1) / np.sum(chan_counts, axis=-1)\n",
    "    # psnrs = 10 * np.mean(np.log(chan_ranges ** 2 / chan_mses), axis=-1)\n",
    "    \n",
    "    # PSNR doesn't matter anyways\n",
    "    psnrs = mses\n",
    "    \n",
    "    return frames, client_tensors, preds, diffs, mses, psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = img.copy()\n",
    "y, x = (np.array(img_.shape[:2]) / 2).astype(int)\n",
    "z = 3\n",
    "img_[y-z:y+z, x-z:x+z] = 0\n",
    "\n",
    "out_width, out_height = 100, 100\n",
    "\n",
    "mat = affine_mat_from(\n",
    "    trans_x=50,\n",
    "    trans_y=0,\n",
    "    rot_deg=0,\n",
    "    shear_x_deg=0, shear_y_deg=0,\n",
    "    scale_x=1, scale_y=1,\n",
    ")\n",
    "\n",
    "# frame = transform(img_, mat, out_width, out_height, leeway=-np.sqrt(2) + 1)\n",
    "frame = transform(img_, mat, out_width, out_height, leeway=0.0)\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = img.copy()\n",
    "y, x = (np.array(img_.shape[:2]) / 2).astype(int)\n",
    "img_[y, x] = 0\n",
    "\n",
    "out_width, out_height = 80, 80\n",
    "# out_width, out_height = 224, 224\n",
    "\n",
    "# mat = affine_mat_from(\n",
    "#     trans_x=39, trans_y=0,\n",
    "#     rot_deg=40,\n",
    "#     shear_x_deg=40, shear_y_deg=-20,\n",
    "#     scale_x=0.8, scale_y=1.1,\n",
    "# )\n",
    "mat = affine_mat_from(\n",
    "    trans_x=39, trans_y=0,\n",
    "    rot_deg=40,\n",
    "    shear_x_deg=40, shear_y_deg=-20,\n",
    "    scale_x=0.8, scale_y=1.1,\n",
    ")\n",
    "# frame = transform(img_, mat, out_width, out_height, leeway=-np.sqrt(2) + 1)\n",
    "frame = transform(img_, mat, out_width, out_height, leeway=0.0)\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_kwargs = dict(\n",
    "    shear_x=(-0.2, 0.2, 0.02),\n",
    "    shear_y=(-0.2, 0.2, 0.02),\n",
    "    scale_x=(0.5, 2.0, 0.1),\n",
    "    scale_y=(0.5, 2.0, 0.1),\n",
    "    rot_deg=(-180.0, 180.0, 1.0),\n",
    "    trans_x=(-300.0, 300.0, 0.1),\n",
    "    trans_y=(-300.0, 300.0, 0.1),\n",
    ")\n",
    "\n",
    "def update_func(\n",
    "    shear_x=0.0,\n",
    "    shear_y=0.0,\n",
    "    scale_x=1.0,\n",
    "    scale_y=1.0,\n",
    "    rot_deg=0.0,\n",
    "    trans_x=0.0,\n",
    "    trans_y=0.0,\n",
    "    fig=None,\n",
    "):\n",
    "    with fig.batch_update():\n",
    "        mat = affine_mat_from(\n",
    "            shear_x=shear_x,\n",
    "            shear_y=shear_y,\n",
    "            scale_x=scale_x,\n",
    "            scale_y=scale_y,\n",
    "            rot_deg=rot_deg,\n",
    "            trans_x=trans_x,\n",
    "            trans_y=trans_y,\n",
    "        )\n",
    "\n",
    "        transform_args = [mat]\n",
    "        \n",
    "        frames, client_tensors, preds, diffs, mses, psnrs = run_experiment(\n",
    "            img, transform_args, predict, transform, runner\n",
    "        )\n",
    "\n",
    "        # Display results\n",
    "\n",
    "        # Adjust for visual purposes\n",
    "        tensors_ = client_tensors\n",
    "        preds_ = preds\n",
    "        diffs_ = np.abs(diffs)\n",
    "\n",
    "        # Show only k channels\n",
    "        koff = 13\n",
    "        k = 3 ** 2\n",
    "        tensors_ = tensors_[..., koff : koff + k]\n",
    "        preds_ = preds_[..., koff : koff + k]\n",
    "        diffs_ = diffs_[..., koff : koff + k]\n",
    "\n",
    "        # Scale colorbar in a consistent manner\n",
    "        clim = (tensors_.min(), tensors_.max())\n",
    "        r = clim[1] - clim[0]\n",
    "        clim_diff = (0, r)\n",
    "\n",
    "        # Manual overrides\n",
    "        clim = (-1.6, 1.4)\n",
    "        clim_diff = (0, 3.0)\n",
    "        \n",
    "        # Plot stuff\n",
    "        fill_value = clim[0] if clim is not None else None\n",
    "        order = \"hwc\"\n",
    "\n",
    "        tensors_ = plot.featuremap_image(tensors_[1], order, fill_value=fill_value)\n",
    "        preds_ = plot.featuremap_image(preds_[0], order, fill_value=fill_value)\n",
    "        diffs_ = plot.featuremap_image(diffs_[0], order, fill_value=fill_value)\n",
    "\n",
    "        image, heatmap, p, d = fig.data\n",
    "        image.z = frames[1]\n",
    "        heatmap.z = tensors_[::-1, :]\n",
    "        p.z = preds_[::-1, :]\n",
    "        d.z = diffs_[::-1, :]\n",
    "        \n",
    "        fig.update_layout(title=f\"MSE: {mses[0]:.3f}\")\n",
    "        # fig.update_layout(title=f\"MSE: {mses[0]:.3f}    PSNR: {psnrs[0]:.1f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "tensor = np.zeros((224, 224), dtype=np.float32)\n",
    "\n",
    "fig = plotly.subplots.make_subplots(\n",
    "    rows=1,\n",
    "    cols=4,\n",
    ")\n",
    "\n",
    "fig.add_traces([\n",
    "    go.Image(z=frame),\n",
    "    go.Heatmap(z=tensor, colorscale=\"Viridis\"),\n",
    "    go.Heatmap(z=tensor, colorscale=\"Viridis\"),\n",
    "    go.Heatmap(z=tensor, colorscale=\"Viridis\"),\n",
    "], cols=[1, 2, 3, 4], rows=1)\n",
    "\n",
    "controllable_fig = go.FigureWidget(fig)\n",
    "controllable_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(**interact_kwargs)\n",
    "def update(shear_x=0.0, shear_y=0.0, scale_x=1.0, scale_y=1.0, rot_deg=0.0, trans_x=0.0, trans_y=0.0):\n",
    "    update_func(shear_x, shear_y, scale_x, scale_y, rot_deg, trans_x, trans_y, fig=controllable_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-interactive figure here\n",
    "\n",
    "import importlib\n",
    "importlib.reload(plot)\n",
    "\n",
    "def plot_overview():\n",
    "    transform_kwargs = [\n",
    "        dict(trans_x=35.0),\n",
    "        dict(rot_deg=10.0),\n",
    "        dict(scale_x=1.2),\n",
    "        dict(shear_x_deg=10.0),\n",
    "    ]\n",
    "\n",
    "    transform_args = [\n",
    "        affine_mat_from(**d) for d in transform_kwargs\n",
    "    ]\n",
    "\n",
    "    frames, client_tensors, preds, diffs, mses, psnrs = run_experiment(\n",
    "        img, transform_args, predict, transform, runner, leeway=1-np.sqrt(2)+0.15,\n",
    "    )\n",
    "\n",
    "    def visual_adjust_tensor(t):\n",
    "        off = t - np.mean(t)\n",
    "        return np.copysign(np.abs(off) ** 0.5, off) + np.mean(t)\n",
    "\n",
    "    # Adjust for visual purposes\n",
    "    tensors_ = visual_adjust_tensor(client_tensors)\n",
    "    preds_ = visual_adjust_tensor(preds)\n",
    "    diffs_ = np.abs(diffs)\n",
    "\n",
    "    # Show only k channels\n",
    "    koff = 0\n",
    "    k = 3 ** 2\n",
    "    tensors_ = tensors_[..., koff : koff + k]\n",
    "    preds_ = preds_[..., koff : koff + k]\n",
    "    diffs_ = diffs_[..., koff : koff + k]\n",
    "\n",
    "    # Scale colorbar in a consistent manner\n",
    "    clim = (tensors_.min(), tensors_.max())\n",
    "    r = clim[1] - clim[0]\n",
    "    clim_diff = (0, r)\n",
    "\n",
    "    # Manual overrides\n",
    "    clim = (-1.6, 1.4)\n",
    "    clim_diff = (0, 3.0)\n",
    "\n",
    "    fig = plot.featuremapsequence(\n",
    "        frames,\n",
    "        tensors_,\n",
    "        preds_,\n",
    "        diffs_,\n",
    "        title=\"\",\n",
    "        clim=clim,\n",
    "        clim_diff=clim_diff,\n",
    "        figsize=(8.0, 10),\n",
    "    )\n",
    "\n",
    "    def idx(y, x):\n",
    "        return 4 * y + x\n",
    "\n",
    "    pad = 6\n",
    "    ax_opts = dict(\n",
    "        xy=(0.5, 1),\n",
    "        xycoords=\"axes fraction\",\n",
    "        xytext=(0, pad),\n",
    "        textcoords=\"offset points\",\n",
    "        size=\"medium\",\n",
    "        ha=\"center\",\n",
    "        va=\"baseline\",\n",
    "    )\n",
    "    axes = fig.axes\n",
    "    axes[idx(0, 0)].annotate(\"Image\", **ax_opts)\n",
    "    axes[idx(0, 1)].annotate(\"Tensor\", **ax_opts)\n",
    "    axes[idx(1, 2)].annotate(\"Motion compensated\\ntensor\", **ax_opts)\n",
    "    axes[idx(1, 3)].annotate(\"Difference\", **ax_opts)\n",
    "    axes[idx(0, 0)].set_ylabel(\"Reference\")\n",
    "    axes[idx(1, 0)].set_ylabel(f\"translate (horizontal)\")\n",
    "    axes[idx(2, 0)].set_ylabel(f\"rotate\")\n",
    "    axes[idx(3, 0)].set_ylabel(f\"stretch (horizontal)\")\n",
    "    axes[idx(4, 0)].set_ylabel(f\"shear (horizontal)\")\n",
    "\n",
    "    plot.save(\n",
    "        fig,\n",
    "        f\"img/experiment/icassp/{runner.basename}-overview.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "        facecolor=\"w\"\n",
    "    )\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "_ = plot_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_range = 56.0\n",
    "k = int(trans_range // x_in_per_cl)\n",
    "a = k * x_in_per_cl\n",
    "xpass_trans = np.linspace(-a, a, 2 * k + 1)\n",
    "\n",
    "m = 4\n",
    "# m = 1\n",
    "samples = 1 * 2**(m + 6) + 1\n",
    "samples_trans = int(trans_range) * 2**(m + 0) + 1\n",
    "\n",
    "experiments = [\n",
    "    {\n",
    "        \"xlabel\": \"Rotation angle (degrees)\",\n",
    "        \"xkwarg\": \"rot_deg\",\n",
    "        \"x\": np.linspace(-180, 180, samples),\n",
    "        # \"x\": np.linspace(-30, 30, samples),\n",
    "        \"xpass\": [0.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Shear angle (degrees)\",\n",
    "        \"xkwarg\": \"shear_x_deg\",\n",
    "        \"x\": np.linspace(-20, 20, samples),\n",
    "        \"xpass\": [0.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Shear angle (degrees)\",\n",
    "        \"xkwarg\": \"shear_y_deg\",\n",
    "        \"x\": np.linspace(-20, 20, samples),\n",
    "        \"xpass\": [0.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Horizontal scale factor\",\n",
    "        \"xkwarg\": \"scale_x\",\n",
    "        \"x\": np.linspace(0.5, 2.0, samples),\n",
    "        \"xpass\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Vertical scale factor\",\n",
    "        \"xkwarg\": \"scale_y\",\n",
    "        \"x\": np.linspace(0.5, 2.0, samples),\n",
    "        \"xpass\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Translation (px)\",\n",
    "        \"xkwarg\": \"trans_x\",\n",
    "        \"x\": np.linspace(-trans_range, trans_range, samples_trans),\n",
    "        \"xpass\": xpass_trans,\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Translation (px)\",\n",
    "        \"xkwarg\": \"trans_y\",\n",
    "        \"x\": np.linspace(-trans_range, trans_range, samples_trans),\n",
    "        \"xpass\": xpass_trans,\n",
    "    },\n",
    "]\n",
    "\n",
    "def run_transform_curve_experiment(experiment):\n",
    "    experiment = dict(experiment)\n",
    "    \n",
    "    x = experiment[\"x\"]\n",
    "    t = experiment.get(\"t\", experiment[\"x\"])\n",
    "    \n",
    "    kwargs = [{experiment[\"xkwarg\"]: v} for v in t]\n",
    "    transform_args = [\n",
    "        affine_mat_from(**d) for d in kwargs\n",
    "    ]\n",
    "    frames, client_tensors, preds, diffs, mses, psnrs = run_experiment(\n",
    "        img, transform_args, predict, transform, runner\n",
    "    )\n",
    "    y = mses\n",
    "    experiment[\"y\"] = y\n",
    "    \n",
    "    # Smoothen curves\n",
    "    window = 2 * int(0.075 * x.size // 2) + 1\n",
    "    y_raw = y\n",
    "    y = signal.savgol_filter(y, window, 3)\n",
    "    if \"xpass\" in experiment:\n",
    "        x0s = np.array(experiment[\"xpass\"])\n",
    "        mask = np.isclose(x[:, np.newaxis], x0s[np.newaxis], atol=2 / x.size, rtol=0)\n",
    "        mask = np.any(mask, axis=-1)\n",
    "        y[mask] = y_raw[mask]\n",
    "    experiment[\"y_smooth\"] = y\n",
    "    \n",
    "    return experiment\n",
    "    \n",
    "def run_transform_curve_experiments(experiments):\n",
    "    prefix = f\"img/experiment/icassp/csv/{runner.basename}-transform_curves\"\n",
    "    results = []\n",
    "    for experiment in experiments:\n",
    "        experiment = run_transform_curve_experiment(experiment)\n",
    "        results.append(experiment)\n",
    "        df = pd.DataFrame({k: experiment[k] for k in [\"x\", \"y\", \"y_smooth\"]})\n",
    "        df.to_csv(f\"{prefix}-{experiment['xkwarg']}.csv\", index=False)\n",
    "    return results\n",
    "\n",
    "def plot_single_transform_curve(x, y, xlabel, xkwarg):\n",
    "    prefix = f\"img/experiment/icassp/{runner.basename}-transform_curves\"\n",
    "    filename = f\"{prefix}-{xkwarg}.png\"\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(x, y)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"NRMSE\")\n",
    "    fig.savefig(filename, dpi=300, facecolor=\"w\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    {\"model_name\": \"resnet34\", \"layer_i\": 3, \"layer_n\": 37, \"layer_name\": \"conv0\"},\n",
    "    {\"model_name\": \"resnet34\", \"layer_i\": 15, \"layer_n\": 37, \"layer_name\": \"add_3\"},\n",
    "    {\"model_name\": \"resnet34\", \"layer_i\": 21, \"layer_n\": 37, \"layer_name\": \"add_7\"},\n",
    "    {\"model_name\": \"densenet121\", \"layer_i\": 32, \"layer_n\": 81, \"layer_name\": \"pool3_pool\"},\n",
    "    {\"model_name\": \"densenet121\", \"layer_i\": 60, \"layer_n\": 81, \"layer_name\": \"pool4_pool\"},\n",
    "]\n",
    "\n",
    "friendly = {\n",
    "    \"resnet34\": \"ResNet-34\",\n",
    "    \"densenet121\": \"DenseNet-121\",\n",
    "}\n",
    "\n",
    "xkwargs = [\n",
    "    \"scale_x\",\n",
    "    \"shear_x_deg\",\n",
    "    \"trans_x\",\n",
    "    \"rot_deg\",\n",
    "]\n",
    "\n",
    "plot_configs = [\n",
    "    {\n",
    "        \"xlabel\": \"Rotation angle (degrees)\",\n",
    "        \"xkwarg\": \"rot_deg\",\n",
    "        \"xrange\": [-10, 10],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Shear angle (degrees)\",\n",
    "        \"xkwarg\": \"shear_x_deg\",\n",
    "        \"xrange\": [-10, 10],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Shear angle (degrees)\",\n",
    "        \"xkwarg\": \"shear_y_deg\",\n",
    "        \"xrange\": [-10, 10],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Horizontal scale factor\",\n",
    "        \"xkwarg\": \"scale_x\",\n",
    "        \"xrange\": [0.8, 1.25],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Vertical scale factor\",\n",
    "        \"xkwarg\": \"scale_y\",\n",
    "        \"xrange\": [0.8, 1.25],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Translation (px)\",\n",
    "        \"xkwarg\": \"trans_x\",\n",
    "        \"xrange\": [-30, 30],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Translation (px)\",\n",
    "        \"xkwarg\": \"trans_y\",\n",
    "        \"xrange\": [-30, 30],\n",
    "    },\n",
    "]\n",
    "\n",
    "all_plot = [\"trans_x\", \"rot_deg\", \"scale_x\", \"shear_x_deg\"]\n",
    "\n",
    "def plot_transform_curves():\n",
    "    png_prefix = f\"img/experiment/icassp/transform_curves\"\n",
    "\n",
    "    for plot_config in plot_configs:\n",
    "        xlabel, xkwarg = itemgetter(\"xlabel\", \"xkwarg\")(plot_config)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        for model_config in model_configs:\n",
    "            basename = basename_of(**model_config)\n",
    "            friendly_config = dict(model_config)\n",
    "            friendly_config[\"model_name\"] = friendly[friendly_config[\"model_name\"]]\n",
    "            title = title_of(**friendly_config)\n",
    "            csv_prefix = f\"img/experiment/icassp/csv/{basename}-transform_curves\"\n",
    "            \n",
    "            df = pd.read_csv(f\"{csv_prefix}-{xkwarg}.csv\")\n",
    "            if \"xrange\" in plot_config:\n",
    "                a, b = plot_config[\"xrange\"]\n",
    "                df[\"x\"] = df.loc[(a <= df[\"x\"]) & (df[\"x\"] <= b)]\n",
    "            ax = sns.lineplot(data=df, x=\"x\", y=\"y_smooth\", label=title)\n",
    "            \n",
    "        ax.set(xlabel=xlabel, ylabel=\"NRMSE\")\n",
    "        ax.set_ylim([0.00, 0.04])\n",
    "\n",
    "        filename = f\"{png_prefix}-{xkwarg}.png\"\n",
    "        fig.savefig(filename, dpi=300, facecolor=\"w\")\n",
    "\n",
    "def plot_transform_curves_all_in_one():\n",
    "    png_prefix = f\"img/experiment/icassp/transform_curves\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8), tight_layout=True)\n",
    "    \n",
    "    pcfgs = [next(d for d in plot_configs if d[\"xkwarg\"] == xkwarg) for xkwarg in all_plot]\n",
    "\n",
    "    for i, plot_config in enumerate(pcfgs):\n",
    "        xlabel, xkwarg = itemgetter(\"xlabel\", \"xkwarg\")(plot_config)\n",
    "        \n",
    "        ax = axes[int(i // 2), i % 2]\n",
    "        plt.sca(ax)\n",
    "\n",
    "        for model_config in model_configs:\n",
    "            basename = basename_of(**model_config)\n",
    "            friendly_config = dict(model_config)\n",
    "            friendly_config[\"model_name\"] = friendly[friendly_config[\"model_name\"]]\n",
    "            title = title_of(**friendly_config)\n",
    "            csv_prefix = f\"img/experiment/icassp/csv/{basename}-transform_curves\"\n",
    "            \n",
    "            df = pd.read_csv(f\"{csv_prefix}-{xkwarg}.csv\")\n",
    "            if \"xrange\" in plot_config:\n",
    "                a, b = plot_config[\"xrange\"]\n",
    "                df[\"x\"] = df.loc[(a <= df[\"x\"]) & (df[\"x\"] <= b)]\n",
    "            _ = sns.lineplot(data=df, x=\"x\", y=\"y_smooth\") #, label=title)\n",
    "            \n",
    "        ax.set(xlabel=xlabel, ylabel=\"NRMSE\")\n",
    "        ax.set_ylim([0.00, 0.04])\n",
    "        ax.tick_params(axis='y', which='minor')\n",
    "        ax.set_yticks(np.linspace(0.00, 0.04, 5))\n",
    "        ax.set_yticks(np.linspace(0.005, 0.035, 4), minor=True)\n",
    "    \n",
    "    labels = []\n",
    "    for model_config in model_configs:\n",
    "        friendly_config = dict(model_config)\n",
    "        friendly_config[\"model_name\"] = friendly[friendly_config[\"model_name\"]]\n",
    "        title = title_of(**friendly_config)\n",
    "        labels.append(title)\n",
    "    \n",
    "    # fig.legend(loc='upper center', bbox_to_anchor=(0.5, 0), bbox_transform=fig.transFigure)\n",
    "    # fig.legend(labels, loc='upper center', bbox_to_anchor=(0.5, 0), bbox_transform=fig.transFigure, ncol=3)\n",
    "    # fig.legend(labels, loc='upper center', ncol=5)\n",
    "    # fig.legend(labels, loc='lower center', ncol=5)\n",
    "    fig.legend(labels, loc='lower center', ncol=5, bbox_to_anchor=(0.5, -0.05),  bbox_transform=fig.transFigure)\n",
    "\n",
    "    filename = f\"{png_prefix}-all.png\"\n",
    "    fig.savefig(filename, dpi=300, bbox_inches='tight', facecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments = run_transform_curve_experiments(experiments)\n",
    "\n",
    "# for experiment in experiments:\n",
    "#     getter = itemgetter(\"x\", \"y_smooth\", \"xlabel\", \"xkwarg\")\n",
    "#     fig = plot_single_transform_curve(*getter(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transform_curves_all_in_one()\n",
    "plot_transform_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    \"shear_x_deg\": {\"min\": -5.0, \"max\": 5.0},\n",
    "    \"shear_y_deg\": {\"min\": -5.0, \"max\": 5.0},\n",
    "    \"scale_x\": {\"min\": 0.95, \"max\": 1.05},\n",
    "    \"scale_y\": {\"min\": 0.95, \"max\": 1.05},\n",
    "    \"rot_deg\": {\"min\": -10.0, \"max\": 10.0},\n",
    "    \"trans_x\": {\"min\": -32.0, \"max\": 32.0},\n",
    "    \"trans_y\": {\"min\": -32.0, \"max\": 32.0},\n",
    "}\n",
    "\n",
    "def rand_params(param_ranges):\n",
    "    return {\n",
    "        k: np.random.rand() * (r[\"max\"] - r[\"min\"]) + r[\"min\"]\n",
    "        for k, r in param_ranges.items()\n",
    "    }\n",
    "\n",
    "def run_random_mse_experiment(batches=32, batch_size=64):\n",
    "    results = []\n",
    "    \n",
    "    for _ in range(batches):\n",
    "        params = [rand_params(param_ranges) for _ in range(batch_size)]\n",
    "        transform_args = [\n",
    "            affine_mat_from(**p) for p in params\n",
    "        ]\n",
    "\n",
    "        frames, client_tensors, preds, diffs, mses, psnrs = run_experiment(\n",
    "            img, transform_args, predict, transform, runner\n",
    "        )\n",
    "        \n",
    "        xs = [{\"mse\": mse, **p} for p, mse in zip(params, mses)]\n",
    "        results.extend(xs)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    prefix = f\"img/experiment/icassp/csv/{runner.basename}-random_mse\"\n",
    "    df.to_csv(f\"{prefix}.csv\", index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_simple_random_mse_experiment(df):\n",
    "    mses = df[\"mse\"].to_numpy()\n",
    "    \n",
    "    arr = mses\n",
    "    clip_range = None\n",
    "    bins = 20\n",
    "\n",
    "    arr = arr.reshape((-1,))\n",
    "    if clip_range is None:\n",
    "        clip_range = (np.min(arr), np.max(arr))\n",
    "    bins_ = np.linspace(*clip_range, bins)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.hist(arr, bins=bins_, density=True)\n",
    "    ax.set_xlabel(\"NRMSE\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    fig.savefig(f\"img/experiment/icassp/{runner.basename}-mse-histogram.png\", dpi=300, facecolor=\"w\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = sns.kdeplot(arr)\n",
    "    ax.set_xlabel(\"NRMSE\")\n",
    "    fig.savefig(f\"img/experiment/icassp/{runner.basename}-mse-density.png\", dpi=300, facecolor=\"w\")\n",
    "    \n",
    "def plot_random_mse_histograms():\n",
    "    png_prefix = f\"img/experiment/icassp/random_mse\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    labels = []\n",
    "\n",
    "    for model_config in model_configs:\n",
    "        basename = basename_of(**model_config)\n",
    "        friendly_config = dict(model_config)\n",
    "        friendly_config[\"model_name\"] = friendly[friendly_config[\"model_name\"]]\n",
    "        title = title_of(**friendly_config)\n",
    "        csv_prefix = f\"img/experiment/icassp/csv/{basename}-random_mse\"\n",
    "\n",
    "        df = pd.read_csv(f\"{csv_prefix}.csv\")\n",
    "        ax = sns.kdeplot(data=df, x=\"mse\", label=title)\n",
    "        labels.append(title)\n",
    "\n",
    "    ax.set(xlabel=\"NRMSE\")\n",
    "    plt.legend(labels)\n",
    "\n",
    "    filename = f\"{png_prefix}.png\"\n",
    "    fig.savefig(filename, dpi=300, facecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = run_random_mse_experiment()\n",
    "# plot_simple_random_mse_experiment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_mse_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps the \"error model\" is roughly the maximum of the decomposed transformation MSEs\n",
    "# Sample space: random (uniform) distributions on params\n",
    "\n",
    "def error_model(reference_curves, **kwargs):\n",
    "    preds = []\n",
    "    for k, v in kwargs.items():\n",
    "        x, y = reference_curves[k]\n",
    "        idx = np.abs(x - v).argmin()\n",
    "        preds.append(y[idx])\n",
    "    preds = np.sort(preds)[::-1]\n",
    "    return preds[0] + 0.8 * preds[1], preds\n",
    "    # return max(preds)\n",
    "\n",
    "def run_error_model_experiment(experiments):\n",
    "    reference_curves = {e[\"xkwarg\"]: (e[\"x\"], e[\"y\"]) for e in experiments}\n",
    "\n",
    "    for k in param_ranges:\n",
    "        x = reference_curves[k][0]\n",
    "        z = param_ranges[k]\n",
    "        assert x.min() <= z[\"min\"]\n",
    "        assert x.max() >= z[\"max\"]\n",
    "\n",
    "    pred_mses = []\n",
    "    preds_mses = []\n",
    "    transform_args = []\n",
    "\n",
    "    for i in range(16):\n",
    "        params = {\n",
    "            k: np.random.rand() * (r[\"max\"] - r[\"min\"]) + r[\"min\"]\n",
    "            for k, r in param_ranges.items()\n",
    "        }\n",
    "        pred_mse, preds_mse = error_model(reference_curves, **params)\n",
    "        mat = affine_mat_from(**params)\n",
    "        pred_mses.append(pred_mse)\n",
    "        preds_mses.append(preds_mse)\n",
    "        transform_args.append(mat)\n",
    "\n",
    "    pred_mses = np.array(pred_mses)\n",
    "    preds_mses = np.array(preds_mses)\n",
    "\n",
    "    frames, client_tensors, preds, diffs, mses, psnrs = run_experiment(\n",
    "        img, transform_args, predict, transform, runner\n",
    "    )\n",
    "\n",
    "    diffs = (pred_mses - mses)\n",
    "    pdiffs = (pred_mses - mses) / mses\n",
    "    print(\"Predicting MSE of an affine transformation\\n\")\n",
    "    print(f\"diff  mean: {np.mean(diffs):.3f}\")\n",
    "    print(f\"diff  std:  {np.std(diffs):.3f}\")\n",
    "    print(\"\")\n",
    "    print(f\"%diff mean: {np.mean(pdiffs):.3f}\")\n",
    "    print(f\"%diff std:  {np.std(pdiffs):.3f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    from itertools import islice\n",
    "\n",
    "    print(\"actual pred   %diff  predictors\")\n",
    "    for actual_mse, pred_mse, preds_mse in islice(zip(mses, pred_mses, preds_mses), 0, 10):\n",
    "        print(\n",
    "            f\"{actual_mse:.3f}  {pred_mse:.3f} \"\n",
    "            f\"{(actual_mse - pred_mse) / actual_mse:>6.3f}  \"\n",
    "            # f\"{(actual_mse - pred_mse) / preds_mse[1]:.3f}\"\n",
    "            f\"{np.round(preds_mse, 3)[:2]} \"\n",
    "        )\n",
    "\n",
    "# Looks like when TWO or more predictions are similarly significant, then MSE is roughly close to their sum?\n",
    "# Or perhaps we should pick the two most significant contributors and take some sort of weighted sum of them?\n",
    "# But does this generalize to other images?\n",
    "# Perhaps an error prediction range is good enough... [a, a + b]\n",
    "# Or we can report the mean error estimate and the error within the error being approximately the mean/2... :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_error_model_experiment(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in runner.model_client.layers:\n",
    "    # print(layer.get_config(), layer.get_weights())\n",
    "    weights = layer.get_weights()\n",
    "    shapes = [x.shape for x in weights]\n",
    "    shapes_str = \"...\" if shapes == [] else str(shapes)\n",
    "    print(layer.name + \"\\n\" + shapes_str)\n",
    "    for w in weights:\n",
    "        if len(w.shape) == 4:\n",
    "            print(w[:, :, 0, 0])\n",
    "            print(np.mean(w, axis=(-1, -2)))\n",
    "#             print(np.std(w, axis=(-1, -2)))\n",
    "            print(np.max(np.abs(w), axis=(-1, -2)))\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_impulse = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "# img_impulse[112, 112] = 255\n",
    "img_impulse[:, 112] = 255\n",
    "img_impulse[112, :] = 255\n",
    "\n",
    "frames = img_impulse[np.newaxis, ...]\n",
    "client_tensors = runner.model_client.predict(frames)\n",
    "t = client_tensors[0]\n",
    "\n",
    "t = t[..., 13:13+9]\n",
    "\n",
    "title = \"cross_1px\"\n",
    "fig = plot.featuremap(t, title, clim=(-2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.save(fig, f\"img/experiment/icassp/tensor_{title}.png\", bbox_inches='tight', facecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def write_video_h264(filename, frames, is_color=True):\n",
    "    height, width = 224, 224\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(\n",
    "        filename, fourcc, fps=10, frameSize=(width, height), isColor=is_color\n",
    "    )\n",
    "\n",
    "    for frame in frames:\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "\n",
    "def generate_videos(experiments):\n",
    "    for experiment in experiments:\n",
    "        xkwarg, x = itemgetter(\"xkwarg\", \"x\")(experiment)\n",
    "        for xkwarg_val in x:\n",
    "            basename = f\"{xkwarg}={xkwarg_val:0.4f}\"\n",
    "            filename = f\"icassp_baseline/input/{basename}.mp4\"\n",
    "            mat_id = affine_mat_from()\n",
    "            img_id = transform(img, mat_id, 224, 224)\n",
    "            mat = affine_mat_from(**{xkwarg: xkwarg_val})\n",
    "            img_trans = transform(img, mat, 224, 224)\n",
    "            frames = [img_id, img_trans]\n",
    "            # print(filename)\n",
    "            write_video_h264(filename, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_range = 56.0\n",
    "k = int(trans_range // x_in_per_cl)\n",
    "a = k * x_in_per_cl\n",
    "xpass_trans = np.linspace(-a, a, 2 * k + 1)\n",
    "\n",
    "m = 0\n",
    "# m = 1\n",
    "samples = 1 * 2**(m + 6) + 1\n",
    "samples_trans = int(trans_range) * 2**(m + 0) + 1\n",
    "\n",
    "experiments_ = [\n",
    "    {\n",
    "        \"xlabel\": \"Rotation angle (degrees)\",\n",
    "        \"xkwarg\": \"rot_deg\",\n",
    "        \"x\": np.linspace(-180, 180, samples),\n",
    "        # \"x\": np.linspace(-30, 30, samples),\n",
    "        \"xpass\": [0.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Shear angle (degrees)\",\n",
    "        \"xkwarg\": \"shear_x_deg\",\n",
    "        \"x\": np.linspace(-20, 20, samples),\n",
    "        \"xpass\": [0.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Shear angle (degrees)\",\n",
    "        \"xkwarg\": \"shear_y_deg\",\n",
    "        \"x\": np.linspace(-20, 20, samples),\n",
    "        \"xpass\": [0.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Horizontal scale factor\",\n",
    "        \"xkwarg\": \"scale_x\",\n",
    "        \"x\": np.linspace(0.5, 2.0, samples),\n",
    "        \"xpass\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Vertical scale factor\",\n",
    "        \"xkwarg\": \"scale_y\",\n",
    "        \"x\": np.linspace(0.5, 2.0, samples),\n",
    "        \"xpass\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Translation (px)\",\n",
    "        \"xkwarg\": \"trans_x\",\n",
    "        \"x\": np.linspace(-trans_range, trans_range, samples_trans),\n",
    "        \"xpass\": xpass_trans,\n",
    "    },\n",
    "    {\n",
    "        \"xlabel\": \"Translation (px)\",\n",
    "        \"xkwarg\": \"trans_y\",\n",
    "        \"x\": np.linspace(-trans_range, trans_range, samples_trans),\n",
    "        \"xpass\": xpass_trans,\n",
    "    },\n",
    "]\n",
    "\n",
    "def generate_videos(experiments):\n",
    "    for experiment in experiments:\n",
    "        xkwarg, x = itemgetter(\"xkwarg\", \"x\")(experiment)\n",
    "        frames = []\n",
    "        filename = f\"img/experiment/icassp/{xkwarg}_tensor.mp4\"\n",
    "        print(filename)\n",
    "        for xkwarg_val in x:\n",
    "            mat_id = affine_mat_from()\n",
    "            img_id = transform(img, mat_id, 224, 224)\n",
    "            mat = affine_mat_from(**{xkwarg: xkwarg_val})\n",
    "            img_trans = transform(img, mat, 224, 224)\n",
    "            frames.append(img_trans)\n",
    "        frames = np.array(frames)\n",
    "        client_tensors = runner.model_client.predict(frames)\n",
    "        t = client_tensors[..., 0][..., np.newaxis]\n",
    "        t = t.astype(np.uint8)\n",
    "        print(len(t))\n",
    "        write_video_h264(filename, t, is_color=False)\n",
    "\n",
    "generate_videos(experiments_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_videos(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, extract motion vectors\n",
    "# Then, compute the frames predicted ONLY from motion vectors\n",
    "# MASK OUT INVALID REGIONS BEFORE COMPUTING NRMSE!\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def estimate_flow_blockmatching(prev_img, next_img, block_size, search_window):\n",
    "    \"\"\"Estimate motion vectors using block matching.\n",
    "\n",
    "    Args:\n",
    "        prev_img: previous frame\n",
    "        next_img: next frame\n",
    "        block_size: size of blocks to match; must be odd integer\n",
    "        search_window: size of square to search; must be odd integer\n",
    "    \"\"\"\n",
    "    h, w = prev_img.shape[:2]\n",
    "\n",
    "    assert prev_img.shape == next_img.shape\n",
    "    assert h >= block_size and w >= block_size\n",
    "    assert block_size % 2 != 0\n",
    "    assert search_window % 2 != 0\n",
    "\n",
    "    block_radius = (block_size - 1) // 2\n",
    "    search_radius = (search_window - 1) // 2\n",
    "\n",
    "    br = block_radius\n",
    "    sr = search_radius\n",
    "\n",
    "    flow = np.zeros((h, w, 2), dtype=np.float64)\n",
    "    err = np.zeros((search_window, search_window), dtype=np.float64)\n",
    "\n",
    "    for y in range(br, h - br):\n",
    "        for x in range(br, w - br):\n",
    "            prev_block = prev_img[y - br : y + br + 1, x - br : x + br + 1]\n",
    "            \n",
    "            # Calculate errors between blocks within search window.\n",
    "            # Search window is within intervals [y2_min, y2_max) and [x2_min, x2_max).\n",
    "            err[:] = np.inf\n",
    "            y2_min = max(0, y - sr - br) + br\n",
    "            x2_min = max(0, x - sr - br) + br\n",
    "            y2_max = min(h, y + sr + br + 1) - br\n",
    "            x2_max = min(w, x + sr + br + 1) - br\n",
    "            \n",
    "            for y2 in range(y2_min, y2_max):\n",
    "                for x2 in range(x2_min, x2_max):\n",
    "                    next_block = next_img[y2 - br : y2 + br + 1, x2 - br : x2 + br + 1]\n",
    "                    ssd = ((next_block - prev_block)**2).sum()\n",
    "                    err[y2 - y + sr, x2 - x + sr] = float(ssd)\n",
    "\n",
    "            # Choose block with lowest error.\n",
    "            i_best = err.argmin()\n",
    "            y_best = i_best // search_window - sr\n",
    "            x_best = i_best % search_window - sr\n",
    "            \n",
    "            flow[y, x, 0] = x_best\n",
    "            flow[y, x, 1] = y_best\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quiver(ax, flow, spacing, margin=0, **kwargs):\n",
    "    \"\"\"Plot less dense quiver field.\n",
    "\n",
    "    Args:\n",
    "        ax: Matplotlib axis\n",
    "        flow: motion vectors\n",
    "        spacing: space (px) between each arrow in grid\n",
    "        margin: width (px) of enclosing region without arrows\n",
    "    \"\"\"\n",
    "    h, w = flow.shape[:2]\n",
    "\n",
    "    nx = int((w - 2 * margin) / spacing)\n",
    "    ny = int((h - 2 * margin) / spacing)\n",
    "\n",
    "    x = np.linspace(margin, w - margin - 1, nx, dtype=np.int64)\n",
    "    y = np.linspace(margin, h - margin - 1, ny, dtype=np.int64)\n",
    "\n",
    "    flow = flow[y][:, x]\n",
    "    u = flow[:, :, 0]\n",
    "    v = -flow[:, :, 1]\n",
    "\n",
    "    ax.quiver(x, y, u, v, **kwargs)\n",
    "\n",
    "\n",
    "# Load images and tensors.\n",
    "filenames  = [\n",
    "    \"/mnt/data/code/android/collaborative-intelligence/data/sample/car/1_crop_224.jpg\",\n",
    "    \"/mnt/data/code/android/collaborative-intelligence/data/sample/car/2_crop_224.jpg\",\n",
    "    # \"/mnt/data/code/android/collaborative-intelligence/data/sample/taxi/sample_frame1_224.jpg\",\n",
    "    # \"/mnt/data/code/android/collaborative-intelligence/data/sample/taxi/sample_frame2_224.jpg\",\n",
    "    # \"/mnt/data/code/android/collaborative-intelligence/data/sample/pinwheel/sample_frame1_224.jpg\",\n",
    "    # \"/mnt/data/code/android/collaborative-intelligence/data/sample/pinwheel/sample_frame2_224.jpg\",\n",
    "]\n",
    "\n",
    "frames = np.array([np.array(Image.open(x)) for x in filenames])\n",
    "img_n, img_h, img_w = frames.shape[:3]\n",
    "\n",
    "if len(frames.shape) == 3:\n",
    "    # If grayscale, convert to RGB.\n",
    "    frames = np.broadcast_to(frames[..., np.newaxis], (*frames.shape, 3))\n",
    "\n",
    "grays = (\n",
    "    np.array([\n",
    "        cv2.cvtColor(frames[0], cv2.COLOR_RGB2GRAY),\n",
    "        cv2.cvtColor(frames[1], cv2.COLOR_RGB2GRAY),\n",
    "    ])\n",
    "    if len(frames.shape) == 4\n",
    "    else frames.copy()\n",
    ")\n",
    "\n",
    "client_tensors = runner.model_client.predict(frames)\n",
    "n, h, w, c = client_tensors.shape\n",
    "\n",
    "# Pre-process client tensors.\n",
    "# from scipy import ndimage\n",
    "# for i in range(n):\n",
    "#     for j in range(c):\n",
    "#         client_tensors[i, ..., j] = ndimage.median_filter(client_tensors[i, ..., j], size=3)\n",
    "\n",
    "# Rescale client tensors.\n",
    "# client_tensors_resized = np.zeros((n, img_h, img_w, c), dtype=client_tensors.dtype)\n",
    "# for i in range(n):\n",
    "#     for j in range(c):\n",
    "#         client_tensors_resized[i, ..., j] = cv2.resize(\n",
    "#             client_tensors[i, ..., j], (img_h, img_w), cv2.INTER_CUBIC\n",
    "#         )\n",
    "# client_tensors = client_tensors_resized\n",
    "# h, w = img_h, img_w\n",
    "\n",
    "# Calculate flow on video frames.\n",
    "# flow = cv2.calcOpticalFlowFarneback(\n",
    "#     # Suggested: 0.5, 3, 15, 3, 5, 1.2, 0\n",
    "#     grays[0],\n",
    "#     grays[1],\n",
    "#     flow=None,\n",
    "#     pyr_scale=0.5,\n",
    "#     levels=3,\n",
    "#     winsize=15,\n",
    "#     iterations=3,\n",
    "#     poly_n=5,\n",
    "#     poly_sigma=1.2,\n",
    "#     flags=0,\n",
    "# )\n",
    "\n",
    "# Calculate flow on video frames.\n",
    "flow = estimate_flow_blockmatching(\n",
    "    grays[0], grays[1], block_size=31, search_window=11\n",
    ")\n",
    "\n",
    "# Rescale input image flow to same width and height as tensor channel.\n",
    "t_flow_expected = np.zeros((h, w, 2), dtype=np.float32)\n",
    "t_flow_expected[..., 0] = cv2.resize(flow[..., 0], (h, w), cv2.INTER_AREA) / (img_w / w)\n",
    "t_flow_expected[..., 1] = cv2.resize(flow[..., 1], (h, w), cv2.INTER_AREA) / (img_h / h)\n",
    "\n",
    "# Calculate flow on client tensors.\n",
    "client_flows = np.zeros((n - 1, h, w, c, 2), dtype=np.float32)\n",
    "\n",
    "for i in range(n - 1):\n",
    "    for j in range(c):\n",
    "        # Skip non-displayed channels.\n",
    "        if j < 13 or j >= 13 + 9:\n",
    "            continue\n",
    "\n",
    "        t_prev = client_tensors[i + 0, ..., j]\n",
    "        t_next = client_tensors[i + 1, ..., j]\n",
    "        t_flow = estimate_flow_blockmatching(\n",
    "            t_prev, t_next, block_size=5, search_window=3\n",
    "        )\n",
    "        client_flows[i, ..., j, :] = t_flow\n",
    "\n",
    "# Reduce red in input image.\n",
    "# r = frames[..., 0]\n",
    "# r[:] = np.maximum(r, grays)\n",
    "\n",
    "# Or perhaps desaturate?\n",
    "saturation = 0.4\n",
    "frames[:] = frames * saturation + (1 - saturation) * grays[..., np.newaxis]\n",
    "\n",
    "# Select k channels from tensor for plot.\n",
    "off, k = 13, 4\n",
    "t = client_tensors[0, ..., off : off + k]\n",
    "t_flow = client_flows[0, ..., off : off + k, :]\n",
    "\n",
    "# Tile tensors (and their flows) into 2D image.\n",
    "t = plot.featuremap_image(t)\n",
    "t_flow = np.concatenate([\n",
    "    plot.featuremap_image(t_flow[..., 0])[..., np.newaxis],\n",
    "    plot.featuremap_image(t_flow[..., 1])[..., np.newaxis],\n",
    "], axis=-1)\n",
    "\n",
    "# Adjust featuremap contrast (modify \"p\" parameter).\n",
    "p = 1.5\n",
    "t_min = t.min()\n",
    "t_max = t.max()\n",
    "t_min = -2.0\n",
    "t_max = 1.5\n",
    "t_min, t_max = (\n",
    "    t_min + 0.5 * (1 - p) * (t_max - t_min),\n",
    "    t_max - 0.5 * (1 - p) * (t_max - t_min),\n",
    ")\n",
    "\n",
    "# Plot.\n",
    "color = \"#ff4477\"\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].imshow(frames[0])\n",
    "plot_quiver(\n",
    "    axes[0],\n",
    "    flow,\n",
    "    spacing=13,\n",
    "    margin=8,\n",
    "    color=color,\n",
    "    scale=0.4,\n",
    "    scale_units=\"x\",\n",
    "    width=0.005 * 2,\n",
    "    # headwidth=3,\n",
    "    # headlength=5,\n",
    "    minshaft=2,\n",
    "    minlength=0.5,\n",
    ")\n",
    "\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].imshow(t, vmin=t_min, vmax=t_max)\n",
    "plot_quiver(\n",
    "    axes[1],\n",
    "    t_flow,\n",
    "    spacing=2.5,\n",
    "    margin=0,\n",
    "    color=color,\n",
    "    scale=0.5,\n",
    "    scale_units=\"x\",\n",
    "    width=0.005,\n",
    ")\n",
    "\n",
    "filename = f\"img/experiment/icassp/{runner.basename}-optical-flow.png\"\n",
    "fig.savefig(filename, dpi=300, facecolor=\"w\", bbox_inches=\"tight\")\n",
    "\n",
    "# Plot single featuremap.\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.axis(\"off\")\n",
    "# ax.imshow(t, vmin=t_min, vmax=t_max)\n",
    "# fig.savefig(\"taxi_featuremap_1.png\", dpi=300, facecolor=\"w\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "# TODO\n",
    "# further quant results\n",
    "# exended cite with arxiv number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = tf.keras.models.load_model(\"models/densenet121/densenet121-full.h5\")\n",
    "# m.summary()\n",
    "# with open(\"img/summary/densenet121.txt\", \"w\") as f:\n",
    "#     m.summary(print_fn=lambda x: f.write(x + \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main:\n",
    "#\n",
    "# Y - plot DenseNet, ResNet multi-layer\n",
    "#   - plot thesis-like \"overview\"\n",
    "# Y - nice looking plots\n",
    "#   - tikz\n",
    "#   - youtube supplement\n",
    "#   - describe experiment, captions\n",
    "\n",
    "# Experimental fixes:\n",
    "#\n",
    "# - rerun experiments on high-resolution image (not 224x224)\n",
    "# - are we computing MSE? or nMSE? or what? should we do nMAE, MAPE, etc?\n",
    "# - how do we compare MSE of different models/layers/channels?\n",
    "# - rerun experiments on larger dataset\n",
    "\n",
    "# Other work:\n",
    "#\n",
    "# - cv2.warpPerspective\n",
    "# - plot actual tensor and predicted color maps with same colorbar (for easier visual comparison)\n",
    "# - use impulse responses to discover interesting info\n",
    "# - determine a \"noise model\"? (Applications: e.g. see if low variance or non-zero mean)\n",
    "# - determine how these transformations influence all N layers afterwards too (can plot on MSE vs param graph)\n",
    "\n",
    "# Q: How does this generalize to other models?\n",
    "\n",
    "# Demonstrate:\n",
    "# - Another (deeper? or shallower) layer of ResNet\n",
    "# - One more classification model: e.g. DenseNet?\n",
    "\n",
    "# Deadline: Oct. 21"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
